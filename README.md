# ğŸ§  Kaggle ML Competitions â€“ Portfolio Repository

![Python](https://img.shields.io/badge/Python-3.8-blue?logo=python) ![Machine Learning](https://img.shields.io/badge/ML-End_to_End_Pipelines-success?logo=scikit-learn) ![Competitions](https://img.shields.io/badge/Kaggle-3_Projects-orange?logo=kaggle) ![Status](https://img.shields.io/badge/Repository-Active-brightgreen)

This repository contains three end-to-end machine learning projects completed as part of Kaggle competitions. Each folder showcases a complete pipelineâ€”from data cleaning and feature engineering to model tuning and final submission. These projects reflect my evolving intuition in handling real-world datasets, building reproducible workflows, and experimenting with ensemble techniques.

---

## ğŸ“ Projects Overview

### âœˆï¸ [Flight Price Prediction](flight-price-prediction)

![ML Type](https://img.shields.io/badge/Task-Regression-blue) ![Model Performance](https://img.shields.io/badge/RÂ²_Score-0.973-purple) ![Status](https://img.shields.io/badge/Project-Completed-brightgreen)

Predict flight ticket prices using structured data.  
Final model: Ensemble of Random Forest and XGBoost  
ğŸ“ˆ RÂ² Score: **0.973**

ğŸ”— [Kaggle Notebook](https://www.kaggle.com/code/drishya23f3001900/iitm-ka1-23f3001900)

---

### ğŸ“‰ [Customer Churn Prediction](customer-churn-prediction)

![ML Type](https://img.shields.io/badge/Task-Classification-red) ![Model Performance](https://img.shields.io/badge/F1_Score-0.6258-purple) ![Status](https://img.shields.io/badge/Project-Completed-brightgreen)

Predict whether a customer will exit a financial institution.  
Final model: Blended ensemble of boosting classifiers  
ğŸ“ˆ F1 Score (submission): **0.6258**  


ğŸ”— [Kaggle Notebook](https://www.kaggle.com/code/drishya23f3001900/iitm-ka2-23f3001900)

---

### ğŸ½ï¸ [Eatery Review Rating Prediction](eatery-review-rating)

![ML Type](https://img.shields.io/badge/Task-NLP_Classification-yellow) ![Model Performance](https://img.shields.io/badge/Accuracy-0.6952-purple) ![Status](https://img.shields.io/badge/Project-Completed-brightgreen)

Predict customer ratings based on textual reviews.  
Final model: Weighted ensemble of XGBoost (60%), HistGradientBoosting (30%), Random Forest (10%)  
ğŸ“ˆ Validation Accuracy: **0.7109**  
ğŸ“ˆ Submission Accuracy: **0.6952**

ğŸ”— [Kaggle Notebook](https://www.kaggle.com/code/drishya23f3001900/23f3001900-ka3) 


## ğŸ“Œ Reflections

Each competition sharpened a different skill:
- ğŸ§¹ Data cleaning and imputation strategies
- ğŸ§  Feature encoding and scaling
- ğŸ” Model selection, tuning, and ensembling
- ğŸ“Š Evaluation under class imbalance and noisy data
- ğŸ“¦ Building reproducible, modular pipelines

This repo is a living archive of my ML journeyâ€”where intuition meets iteration.

---
