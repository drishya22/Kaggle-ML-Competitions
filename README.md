# 🧠 Kaggle ML Competitions – Portfolio Repository

![Python](https://img.shields.io/badge/Python-3.8-blue?logo=python) ![Machine Learning](https://img.shields.io/badge/ML-End_to_End_Pipelines-success?logo=scikit-learn) ![Competitions](https://img.shields.io/badge/Kaggle-3_Projects-orange?logo=kaggle) ![Status](https://img.shields.io/badge/Repository-Active-brightgreen)

This repository contains three end-to-end machine learning projects completed as part of Kaggle competitions. Each folder showcases a complete pipeline—from data cleaning and feature engineering to model tuning and final submission. These projects reflect my evolving intuition in handling real-world datasets, building reproducible workflows, and experimenting with ensemble techniques.

---

## 📁 Projects Overview

### ✈️ [Flight Price Prediction](flight-price-prediction)

![ML Type](https://img.shields.io/badge/Task-Regression-blue) ![Model Performance](https://img.shields.io/badge/R²_Score-0.973-purple) ![Status](https://img.shields.io/badge/Project-Completed-brightgreen)

Predict flight ticket prices using structured data.  
Final model: Ensemble of Random Forest and XGBoost  
📈 R² Score: **0.973**

🔗 [Kaggle Notebook](https://www.kaggle.com/code/drishya23f3001900/iitm-ka1-23f3001900)

---

### 📉 [Customer Churn Prediction](customer-churn-prediction)

![ML Type](https://img.shields.io/badge/Task-Classification-red) ![Model Performance](https://img.shields.io/badge/F1_Score-0.6258-purple) ![Status](https://img.shields.io/badge/Project-Completed-brightgreen)

Predict whether a customer will exit a financial institution.  
Final model: Blended ensemble of boosting classifiers  
📈 F1 Score (submission): **0.6258**  


🔗 [Kaggle Notebook](https://www.kaggle.com/code/drishya23f3001900/iitm-ka2-23f3001900)

---

### 🍽️ [Eatery Review Rating Prediction](eatery-review-rating)

![ML Type](https://img.shields.io/badge/Task-NLP_Classification-yellow) ![Model Performance](https://img.shields.io/badge/Accuracy-0.6952-purple) ![Status](https://img.shields.io/badge/Project-Completed-brightgreen)

Predict customer ratings based on textual reviews.  
Final model: Weighted ensemble of XGBoost (60%), HistGradientBoosting (30%), Random Forest (10%)  
📈 Validation Accuracy: **0.7109**  
📈 Submission Accuracy: **0.6952**

🔗 [Kaggle Notebook](https://www.kaggle.com/code/drishya23f3001900/23f3001900-ka3) 


## 📌 Reflections

Each competition sharpened a different skill:
- 🧹 Data cleaning and imputation strategies
- 🧠 Feature encoding and scaling
- 🔍 Model selection, tuning, and ensembling
- 📊 Evaluation under class imbalance and noisy data
- 📦 Building reproducible, modular pipelines

This repo is a living archive of my ML journey—where intuition meets iteration.

---
